{
  "author": {
    "name": "cubejs"
  },
  "contributors": [
    {
      "name": "Roy Zhou",
      "email": "huzhou@ebay.com"
    }
  ],
  "repository": {
    "type": "git",
    "url": "https://github.com/cubejs/cluster2.git"
  },
  "name": "cluster2",
  "version": "0.5.0-SNAPSHOT.1386026260255",
  "engines": {
    "node": ">= 0.10.0"
  },
  "main": "lib/index.js",
  "dependencies": {
    "underscore": "~1.4.4",
    "usage": "~0.3.8",
    "when": "~2.3.0",
    "winston": "~0.7.2",
    "graceful-fs": "~2.0.0",
    "request": "~2.21.0",
    "express": "~3.1.0",
    "socket.io": "~0.9.16",
    "ejs": "~0.8.4",
    "node-inspector": "~0.4.0",
    "gc-stats": "~0.0.1",
    "bignumber.js": "~1.1.1",
    "npm": "~1.3",
    "optimist": "~0.6.0"
  },
  "devDependencies": {
    "mocha": "~1.11.0",
    "should": "~1.2.2",
    "dustjs-linkedin": "~2.0.3",
    "dustjs-helpers": "~1.1.1",
    "consolidate": "~0.9.1"
  },
  "scripts": {
    "prestart": "rm -rf ./log; mkdir log; rm -rf ./pids; mkdir pids",
    "start": "node ./examples/cluster-demo.js --port=9090 --monPort=9091 --noWorkers=2 --cache.enable --heartbeat.interval=5000 &",
    "stop": "node shutdown.js",
    "pretest": "rm -rf ./log; mkdir log; rm -rf ./pids; mkdir pids",
    "test": "mocha --ui bdd --timeout 10s --reporter spec  ./test/*-test.js"
  },
  "publishConfig": {
    "registry": "https://registry.npmjs.org"
  },
  "ebay": {},
  "readme": "cluster2\n===============\n\nThis is a completely overhaul, not expected to be backward compatible, but the features should cover the most popular while some changes are on their way:\n\n## simplification\n\nYou'll see that we've simplified the api a great deal, no more cluster class, instance to worry, a single #listen method to take all dancing parts.\nAnd those configurable pieces mostly have reasonable defaults, and could be easily set from command line arguments. For example, `--port=8080`, `--cache.enable` etc.\nAlso we've adopted Promise A+ (when.js). style to replace the callbacks, we like it for the fewer level of nested code, a lot. \nYou'll also find some redundant features like: multiple app/port support, ecv on workers, none cluster mode, all removed to keep code compact.\n\n* **`cluster`**\n\n```javascript\nvar listen = require('cluster2').listen;\n\nlisten({\n\n  'noWorkers': 1, //default number of cpu cores\n\t'createServer': require('http').createServer,\n\t'app': app, //your express app\n\t'port': 9090, //express app listening port\n\t'configureApp': function(app){\n\t\t//register your routes, middlewares to the app, must return value or promise\n\t\treturn app;\n\t},\n\t'warmUp': function(app, address){\n\t\t//warm up your application, must return value or promise\n\t\treturn app;\n\t},\n\t'warmUpPort': 9093, //the port to do warmup, after which, server will be stopped, and restarted on the actual port\n\t'debug': { //node-inspector integration\n\t\t'webPort': 9092, //node-inspector web listening port\n\t\t'saveLiveEdit': true\n\t},\n\t'ecv': {\n\t\t'mode': 'control',\n\t\t'root': '/ecv'\n\t},\n\t'cache': {\n\t\t'enable': true, //check cache section\n\t\t'mode': 'standalone' //default creates a standalone worker specific to run as cache manager, otherwise use master to run\n\t},\n\t'gc': {\n\t\t'monitor': true,  //will reflect the gc (incremental, full) in heartbeat, this conflicts with socket.io somehow\n\t\t'idle-noitification': false, //for performance reason, we'll disable node idle notification to v8 by default\n \t\t'explicit': false //yet impl, meant to expose gc() as a global function\n\t},\n\t'monCreateServer': require('http').createServer, //tell master what mon app server should be created as\n\t'monConfigureApp': function(monApp){//could overwrite with your own monitor app, and configure it\n\t\treturn monApp;\n\t},\n\t'monApp': monApp,\n\t'monPort': 9091, //monitoring app listening port\n  \t'maxAge': 3600, //worker's max life in seconds, default is 3 days\n\t'heartbeatInterval': 5000 //heartbeat interval in MS\n})\n.then(function(resolved){\n   //cluster started\n   //resolved is an object which embeds server, app, port, etc.\n   //this is quite useful, you must understand that both master and workers will get to here (due to fork)\n   //if it's worker, it means the warmup of that worker process has been finished (and listening already happen of course)\n   //if it's master, it means all of the workers (noWorkers) asked to be created initially have all been warmed up\n   //and implicitly, the ecv if enabled, will return 200 to whoever polls for the status\n})\n.otherwise(function(error){\n  //cluster start error\n});\n//the major change is the return of promise and the much simplified #listen (as all options pushed to construction)\n\n```\n\n## application flow\n\nFor this cluster2 to work perfect, you might need to accept some of the assumption we made of your application flow. It exists to make your life easier, so as for our middleware registration to work as expected.\nThe flow is as the following:\n\n* master starts `listen`\n* master configures `monApp` with given `monConfigureApp`\n* master starts `caching` service if enabled\n* master creats server using `monCreateServer` and takes in configured `monApp`\n* master starts server on the `monPort` and wait for `listening` event\n* master starts forking workers\n* worker starts `listen`\n* worker configures `app` with given `configureApp`\n* worker creates server using `createServer` and takes in configured `app`\n* worker starts server on `warmUpPort` and wait for `listening` event\n* worker receives `listening` event and starts `warmup`\n* worker waits for `warmup` to complete and stops the warmup server\n* worker starts server on actual `port` and wait for `listening` event\n* worker receives `listening` event and notify master that it's ready to serve traffic\n* worker resolves the `promise` returned by `listen`\n* master receives notifications from all workers then mark up `ecv`\n* master then resolves the `promise` returned by `listen` \n\nA few key points: \n* The abstract pattern is the same for master & worker (different in what's done in each step): **listen** -> **configure app** -> **create server** -> **warmup** -> **start listening** -> **resolve promise**\n* Caching service starts early, so that you could start using cache whether in master or worker, after **configure app**\n* WarmUp is added as an explicit step to allow application to be performant when the traffic is on.\n* Configure app, and warmup could return value (app) or promise which resolves to the app. \n \nA clear flow as above allows users to inject their middleware, routes, warm up their application in a deterministic manner.\nAnd we could leverage this, so that we could safely register middleware like tps collection in front of users'. This makes testing much easier too,\nas the promise won't be resolved till the server actually starts, no more timed waiting, event emitting etc. You're good to request anything by then.\n\n## emitter\n\nCluster used to be an emitter itself, which isn't very much helpful, and forced event register/emit to be delayed till the cluster instance is created.\nEven if it's created, accessing the instance from different modules require the instance to be passed down, or global, neither looks appealing.\nThe new cluster-emitter is designed to work with cluster not cluster2 instance at all (in fact, we eliminated the cluster2 instance as you see the api above)\nThe emitter also makes communications between worker & master (or reverse) as simple as a normal EventEmitter.\n\n```javascript\nvar emitter = require('cluster2/emitter');\n\nemitter.on('event', function callback(){\n\t//an event callback\n});\n\nemitter.once('event', function callbackOnce(){\n\t//another event callback\n});\n\nemitter.removeListener('event', callback);\nemitter.removeListener('event', callbackOnce);\nemitter.removeAllListeners('event');\n\nemitter.emit('event', 'arg0', 'arg1');\n//it varies in master and worker runtime, in master it's the same as saying\nemitter.emitTo(['self'].concat(_.map(cluster.workers, function(w){return w.process.pid;})), ['event', 'arg0', 'arg1']);\n//as this indicates, the master's emit target by default is everybody, master itself and all active workers\n//and in worker runtime, it's intepreted as worker itself and master\nemitter.emitTo(['self', 'master'], ['event', 'arg0', 'arg1']);\n//you don't have to use the different `emitTo` method unless you have a different targets set from the default explained above.\n//but in cause you need, it's also simplified as:\nemitter.to(['master']).emit('event', 'arg0', 'arg1');\n//use to method to scope the target differently, the value should be an array of pids, or 'master', or 'self'\n\n```\n\n## ecv\n\nECV is a preserved feature, but we've simplified that too. Most of the use cases we've seen doesn't really need an ECV for each worker process, in fact\nthat could be very confusing. To let tools view the cluster as an entirety, ECV is to run only in master runtime, it still supports the 'monitor' vs. 'control' mode.\n\n```javascript\n\n//ecv control could be used as such\nvar enable = require('cluster2/ecv').enable;\n\nenable(app);\n\n//more use cases just let cluster2 enables it by passing configurations to the #listen\nvar listen = require('cluster2').listen;\n\nlisten({\n\n  'noWorkers': 1, //default number of cpu cores\n\t'createServer': require('http').createServer,\n\t'app': app,\n\t'port': 9090,\n\t'monPort': 9091,\n\t'debug': { //node-inspector integration\n\t\t'webPort': 9092,\n\t\t'saveLiveEdit': true\n\t},\n\t'ecv': {\n\t\t'mode': 'control',//could be 'monitor' or 'control'\n\t\t'root': '/ecv',\n\t\t'markUp': '/ecv/markUp',\n      \t\t'markDown': '/ecv/markDown'\n\t},\n\t'heartbeatInterval': 5000 //heartbeat rate\n});\n\n//alternatively\n\nlisten({\n\n  'noWorkers': 1, //default number of cpu cores\n\t'createServer': require('http').createServer,\n\t'app': app,\n\t'port': 9090,\n\t'monPort': 9091,\n\t'debug': { //node-inspector integration\n\t\t'webPort': 9092,\n\t\t'saveLiveEdit': true\n\t},\n\t'ecv': {\n\t\t'mode': 'monitor',//could be 'monitor' or 'control'\n\t\t'root': '/ecv',\n\t\t'monitor': '/myapplication/route1',\n      \t\t'validator': function(err, response, body){\n      \t\t\t//to validate what we got from the monitor url\n      \t\t\treturn true;//or false\n      \t\t}\n\t},\n\t'heartbeatInterval': 5000 //heartbeat rate\n});\n```\n\n## debug\n\nEver imagined debugging to be simpler? Here's the good news, we've carefully designed the debugging process from the ground up of the new cluster.\nWith integration with ECV, worker lifecycle management, node-inspector, and bootstrap + websocket debug app (middleware to be exact). You're now\nable to debug any running worker a few clicks away, same applies for a newly forked one.\n\n`http://localhost:9091/debug` (change host, port to your configured values) `debug` route is what we added as a middleware to the monitor app given. It presents an insight of the running workers, their health; in addition, the cluster cache status. You could hover on a worker pid to request a node-inspector based debug, the control flow is described at `__dirname/lib/public/images/live-debugging.png`.\n\nThe experience is designed to be the same across different environments, whether dev, qa, or even production, the same debugging flow and mechanism would make diagnostics much more effective.\n\n## deps\n\nThis is a preserved feature of cluster2, it simply list the npm ls result and give it under `http://localhost:9091/deps` route, which looks like the following.\n\n```javascript\n{\n  \"name\": \"cluster2\",\n  \"version\": \"0.5.0\",\n  \"dependencies\": {\n    \"underscore\": {\n      \"version\": \"1.4.4\",\n      \"from\": \"underscore@~1.4.4\"\n    },\n    \"usage\": {\n      \"version\": \"0.3.8\",\n      \"from\": \"usage@~0.3.8\",\n      \"dependencies\": {\n        \"bindings\": {\n          \"version\": \"1.1.1\",\n          \"from\": \"bindings@1.x.x\"\n        }\n      }\n    },\n    \"when\": {\n      \"version\": \"2.3.0\",\n      \"from\": \"when@~2.3.0\"\n    },\n    \"graceful-fs\": {\n      \"version\": \"2.0.1\",\n      \"from\": \"graceful-fs@~2.0.0\"\n    },\n    \"gc-stats\": {\n      \"version\": \"0.0.1\",\n      \"from\": \"gc-stats@~0.0.1\",\n      \"resolved\": \"https://registry.npmjs.org/gc-stats/-/gc-stats-0.0.1.tgz\"\n    },\n    \"bignumber.js\": {\n      \"version\": \"1.1.1\",\n      \"from\": \"bignumber.js@~1.1.1\"\n    }\n    //... more dependencies not shown\n  }\n}\n```\n\n## robustness\n\nThis is sth we learned given the real experience of a node.js application, workers do get slower, whether that's memory leak, or GC becomes worse, it's easier to prepare\nthan to avoid. So as a step forward from the previous 'death watch', we're now proactively collecting performance statistics and to decide it a worker could be ended \nbefore it gets slow. You could see the simple heurstic we put at `__dirname/lib/utils.js` # `assertOld` function. You can always overwrite this based on your application's characteristics, but this gives a good starting point based on heartbeat collected stats.\n\n```javascript\n\nexports.assertOld = function assertOld(maxAge){\n\n  maxAge = maxAge || 3600 * 24 * 3;//3 days\n\n  return function(heartbeat){\n  \n    return heartbeat.uptime >= maxAge;\n  };\n};\n\nexports.assertBadGC = function assertBadGC(){\n\n  var peaks = {};\n\n  return function(heartbeat){\n\n    var pid = heartbeat.pid,\n        uptime = heartbeat.uptime,\n          currTPS = heartbeat.tps || (heartbeat.transactions * 1000 / heartbeat.cycle);\n\n      if(currTPS <= 2){//intelligent heuristic, TPS too low, no good for sampling as the 1st phase.\n          return false;\n      }\n\n      var peak = peaks[pid] = peaks[pid] || {\n              'tps': currTPS,\n              'cpu': heartbeat.cpu,\n              'memory': heartbeat.memory,\n              'gc': {\n                  'incremental': heartbeat.gc.incremental,\n                  'full': heartbeat.gc.full\n              }\n          };//remember the peak of each puppet\n\n      if(currTPS >= peak.tps){\n          peak.tps = Math.max(heartbeat.tps, peak.tps);\n          peak.cpu = Math.max(heartbeat.cpu, peak.cpu);\n          peak.memory = Math.max(heartbeat.memory, peak.memory);\n          peak.gc.incremental = Math.max(heartbeat.gc.incremental, peak.gc.incremental);\n          peak.gc.full = Math.max(heartbeat.gc.full, peak.gc.full);\n      }\n      else if(currTPS < peak.tps * 0.9 //10% tps drop\n          && heartbeat.cpu > peak.cpu\n          && heartbeat.memory > peak.memory\n          && heartbeat.gc.incremental > peak.gc.incremental\n          && heartbeat.gc.full >= peak.gc.full){//sorry, current gc.full is usually zero\n          \n          return true;\n      }\n\n      return false;\n  }\n};\n\n{\n  'shouldKill': options.shouldKill || (function(){ //default assertions for killing a worker\n\n    var assertions = [assertOld(_this.maxAge), assertBadGC()];\n\n    return function(heartbeat){\n\n      return _.some(assertions, function(a){\n\n        return a(heartbeat);\n      });\n    };\n    \n  })()\n}\n\n```\n\nApart from the above mentioned proactive collection, we noticed another subtle issue in practice. When a worker is dead, its load will be distributed to the rest of alives certainly, that adds some stress to the alives, but when more than one worker died at the same time, the stress could become problem.\nTherefore, to prevent such from happening when worker is marked to be replaced, we made it a FIFO, further explained in `__dirname/lib/utils` # `deathQueue` function. Its purpose is to guarantee that no more than one worker could commit suicide and be replaced at the same time.\n\n```javascript\n\nexports.deathQueue = (function(){\n\n\tvar tillPrevDeath = null,\n\t\tqueued = [];\n\n\treturn function deathQueue(pid, emitter, success, options){\n\n\t\toptions = options || {};\n\n\t\tassert.ok(pid);\n\t\tassert.ok(emitter);\n\t\tassert.ok(success);\n\n\t\tvar wait = options.timeout || 60000,\n\t\t\tdeath = util.format('worker-%d-died', pid),\n\t\t\tlogger = options.logger || {\n\t\t\t\t'debug' : function(){\n\t\t\t\t\tconsole.log.apply(console, arguments);\n\t\t\t\t}\n\t\t\t};\n\n\t\tif(!_.contains(queued, pid)){\n\n\t\t\tqueued.push(pid);\n\n\t\t\tvar tillDeath = when.defer(),\n\t\t\t\tafterDeath = null,\n\t\t\t\tdie = function(){\n\n\t\t\t\t\tvar successor = success();\n\n\t\t\t\t\t//when successor is in place, the old worker could be discontinued finally\n\t\t\t\t\temitter.once(util.format('worker-%d-warmup', successor.process.pid), function(){\n\n\t\t\t\t\t\tlogger.debug('[deathQueue] successor:%d of %d warmup', successor.process.pid, pid);\n\n\t\t\t\t\t\temitter.to(['master', pid]).emit('disconnect', pid);\n\n\t\t\t\t\t\temitter.once(death, function(){\n\n\t\t\t\t\t\t\tlogger.debug('[deathQueue] %d died', pid);\n\n\t\t\t\t\t\t\ttillDeath.resolve(pid);\n\n\t\t\t\t\t\t\tif(tillPrevDeath === afterDeath){//last of dyingQueue resolved, clean up the dyingQueue\n\n\t\t\t\t\t\t\t\tlogger.debug('[deathQueue] death queue cleaned up');\n\n\t\t\t                    tillPrevDeath = null;\n\t\t\t\t\t\t\t}\n\t\t\t            });\n\n\t\t\t            setTimeout(function(){\n\n\t\t\t            \tif(!exports.safeKill(pid, 'SIGTERM', logger)){//worker still there, should emit 'exit' eventually\n\n\t\t\t\t            \tlogger.debug('[deathQueue] worker:%d did not report death by:%d, kill by SIGTERM', pid, wait);\n\t\t\t            \t}\n\t\t\t            \telse{//suicide or accident already happended, process has run away\n\t\t\t            \t\t//we emit this from master on behalf of the run away process.\n\n\t\t\t            \t\tlogger.debug('[deathQueue] worker:%d probably ran away, emit:%s on behalf', death);\n\n\t\t\t            \t\temitter.to(['master']).emit(death);\n\t\t\t            \t}\n\n\t\t\t            }, wait);\n\t\t\t\t\t});\n\t\t\t\t};\n\n\t\t\tif(!tillPrevDeath){//1st in the dying queue,\n\t\t\t\tafterDeath = tillPrevDeath = tillDeath.promise;//1 min\n\t\t\t\tdie();\n\t\t\t}\n\t\t\telse{\n\t\t\t\tafterDeath = tillPrevDeath = tillPrevDeath.ensure(die);\n\t\t\t}\n\t\t}\n\t};\n\t\n})();\n\n```\n\nOh, one more thing, much as we hope that all workers will behave well, let us know when it's going to give up, in reality, they might not.\nFor an additional level of protection, we added a simple `nanny` monitor to our master, which simply collects each workers' last `heartbeat` event and check if any possible **runaway** happened.\nOnce detected, it will be treated the same as a suicide event, using the above `deathQueue`. This will ensure you won't have a cluster running fewer and fewer workers.\n\n```javascript\n\nexports.nanny = function nanny(puppets, emitter, success, options){\n\n\tassert.ok(puppets);\n\tassert.ok(emitter);\n\tassert.ok(success);\n\n\toptions = options || {};\n\n\tvar tolerance = options.tolerance,\n\t\tnow = Date.now();\n\n\t_.each(puppets, function(p){\n\n\t\tif(now - p.lastHeartbeat > tolerance){\n\n\t\t\texports.deathQueue(p.pid, emitter, success, options);\n\t\t\t\n\t\t}\n\t});\n};\n```\n\n## caching\n\nThis is as exciting as debugging, it allows workers to share computation results, watch over changes, in a fast and reliable manner.\nWe tried work delegation to master once, and found it error-prone and difficult to code against, caching makes things so much simpler, using domain socket, so much faster.\nThe atomic getOrLoad syntax makes sharing efficient, running cache manager as another worker and persistence support make it disaster recoverable.\nIt's like having a memcached process, only this is node, and you can debug it too.\n\n* **`cache`** \n\n```javascript\nvar cache = require('cluster2/cache').use('cache-name', {\n  'persist': true,//default false\n  'expire': 60000 //in ms, default 0, meaning no expiration\n});\n\n```\n* **`keys`**\n\n```javascript\nvar cache;//assume the cache is in use as above\n\ncache.keys({\n  'wait': 100//this is a timeout option\n})\n.then(function(keys){\n//the keys resolved is an array of all cached keys:string[] from the cache-manager's view\n});\n\n//to use the cache, we assume u've started the cluster2 with caching enabled, and you can select how cache manager should be run\nlisten({\n\n  'noWorkers': 1, //default number of cpu cores\n\t'createServer': require('http').createServer,\n\t'app': app,\n\t'port': 9090,\n\t'monPort': 9091,\n\t'debug': { //node-inspector integration\n\t\t'webPort': 9092,\n\t\t'saveLiveEdit': true\n\t},\n\t'ecv': {\n\t  'mode': 'control',\n\t  'root': '/ecv'\n\t},\n\t'cache': {\n\t\t'enable': true,//true by default\n\t\t'mode': 'standalone'//as a standalone worker process by default, otherwise will crush with the master process\n\t},\n\t'heartbeatInterval': 5000 //heartbeat rate\n})\n```\n\nNote that, we allow you to use caching w/o cluster2, if you want to enable caching from none cluster2 runtime, the feature could be enabled via:\n\n```javascript\n\n//you can use this in unit test too as we did\nrequire('cluster2/cache').enable({\n\t'enable': true\n});\n\n```\n\n* **`get`** \n* with the loader, if concurrent `get` happens across the workers in a cluster, only one will be allowed to **load** while the rest will be in fact `watch` till that one finishes loading.\n* this will reduce the stress upon the backend services which loads exact same data nicely\n\n```javascript\nvar cache;\n\ncache.get('cache-key-1', //key must be string\n  function(){\n    return 'cache-value-loaded-1'; //value could be value or promise\n  },\n  {\n    'wait': 100//this is a timeout option\n  })\n  .then(function(value){\n    //the value resolved is anything already cached or the value newly loaded\n    //note, the loader will be called once and once only, if it failed, the promise of get will be rejected.\n  })\n  .otherwise(function(error){\n  \n  });\n```\n* **`set`**\n\n```javascript\nvar cache;\n\ncache.set('cache-key-1', //key must be string\n  'cache-value-loaded-1', //value could be any json object\n  {\n    'leaveIfNotNull': false,//default false, which allows set to overwrite existing values\n    'wait': 100\n  })\n  .then(function(happens){\n    //the happens resolved is a true/false value indicating if the value has been accepted by the cache manager\n  })\n  .otherwise(function(error){\n  \n  });\n```\n* **`del`**\n\n```javascript\nvar cache;\n\ncache.del('cache-key-1', //key must be string\n  {\n    'wait': 100//this is a timeout option\n  })\n  .then(function(value){\n    //the old value deleted\n  });\n```\n* **`watch`**\n\n```javascript\nvar cache;\n\ncache.watch('cache-key-1', //key must be string or null (indicating watch everything)\n  function watching(value, key){\n    //this is a callback which will be called anytime the associatd key has an updated value\n  });\n```\n* **`unwatch`**\n\n```javascript\nvar cache;\n\ncache.unwatch('cache-key-1', watching);//stop watching\n```\n\n## status\n\nThis is a helpful piece evolved from the current cluster2, which is to allow applications to easily register status of any interest.\nIt allows each worker to register its own state, master would automatically aggregate all states from active workers.\nIt works nicely with our monitor capability (via debug middleware)\n\n* **`register`**\n\n```javascript\nrequire('cluster2/status')\n  .register('status-name',\n    function(){\n      return 'view';//view function\n    },\n    function(value){\n      //update function\n    });\n```\n\n* **`statuses`**\n\n```javascript\nrequire('cluster2/status')\n  .statuses(); //return names of registered statuses\n```\n\n* **`getStatus`**\n\n```javascript\nrequire('cluster2/status')\n  .getStatus('status-name')\n  .then(function(status){\n    //got status\n  })\n  .otherwise(function(error){\n    //err\n  });\n```\n\n* **`setStatus`**\n\n```javascript\nrequire('cluster2/status')\n  .setStatus('status-name',\n    'value')\n  .then(function(set){\n    //set or not\n  })\n  .otherwise(function(error){\n    //err\n  });\n```\n",
  "readmeFilename": "README.md",
  "description": "cluster2 ===============",
  "bugs": {
    "url": "https://github.com/cubejs/cluster2/issues"
  },
  "homepage": "https://github.com/cubejs/cluster2",
  "_id": "cluster2@0.5.0-SNAPSHOT.1386026260255",
  "dist": {
    "shasum": "7c915d40f654b214e2bcd2bb140c204e078a408e"
  },
  "_from": "cluster2@0.5.0-SNAPSHOT.1386026260255",
  "_resolved": "https://registry.npmjs.org/cluster2/-/cluster2-0.5.0-SNAPSHOT.1386026260255.tgz"
}
